[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tobias Anton",
    "section": "",
    "text": "With a passion for telling stories with data, I’m especially interested in data visualisation and the psychological and perceptual pitfalls thereof. Please have a look at my github profile or my projects here to get an impression of my work.\n\n\nAnalysis Ready Data Development | Data Scientist / R-Developer | June 2023 - Aug 2024\nAdvanced Bayesian Data Analysis | Research Assistant / Tutor | April 2021 - Sept 2021\nQuantitative Methods I & II | Lecturer / Tutor | Oct 2015 - Sept 2018\n\n\n\nM. Sc. Cogntive Science | Artificial Intelligence & Cognitive Psychology\nUniversität Osnabrück | Oct 2018 - Dec 2022\nB. Sc. Psychology | Work- and Organisational Psychology and Neuroscience\nUniversität Bremen | Oct 2014 - June 2018"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Tobias Anton",
    "section": "",
    "text": "Analysis Ready Data Development | Data Scientist / R-Developer | June 2023 - Aug 2024\nAdvanced Bayesian Data Analysis | Research Assistant / Tutor | April 2021 - Sept 2021\nQuantitative Methods I & II | Lecturer / Tutor | Oct 2015 - Sept 2018"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Tobias Anton",
    "section": "",
    "text": "M. Sc. Cogntive Science | Artificial Intelligence & Cognitive Psychology\nUniversität Osnabrück | Oct 2018 - Dec 2022\nB. Sc. Psychology | Work- and Organisational Psychology and Neuroscience\nUniversität Bremen | Oct 2014 - June 2018"
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "R Packages",
    "section": "",
    "text": "A convenient way to access the spotify API in bulk in a tidyverse-y way. This package never got around to find a convenient way to initialize thing"
  },
  {
    "objectID": "packages.html#tadaa-spotify",
    "href": "packages.html#tadaa-spotify",
    "title": "R Packages",
    "section": "",
    "text": "A convenient way to access the spotify API in bulk in a tidyverse-y way. This package never got around to find a convenient way to initialize thing"
  },
  {
    "objectID": "packages.html#ddater",
    "href": "packages.html#ddater",
    "title": "R Packages",
    "section": "ddateR",
    "text": "ddateR\nHail Eris! A perpetual date converter from the gregorian to the poee calendar. Basically an R implementation of the ddate function from util-linux."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Stylized Map of Bremen\n\n\nUsing publicly available shapefiles and ggplot2\n\n\n\n\nsf\n\n\ngeospatial\n\n\nvisualisation\n\n\n \n\n\n\n\nSep 9, 2024\n\n\nTobias\n\n\n\n\n\n\n  \n\n\n\n\nsugr: make it shiny\n\n\nA shiny app to conveniently browse blood glucose history\n\n\n\n\nshiny\n\n\ntimeseries\n\n\nmedical\n\n\nETL\n\n\nvisualisation\n\n\n \n\n\n\n\nAug 4, 2024\n\n\nTobias\n\n\n\n\n\n\n  \n\n\n\n\nsugr: data preparation\n\n\nPreparation of Continouos Glucose Measurements for usage in a shiny app\n\n\n\n\ndata cleaning\n\n\ntimeseries\n\n\nmedical\n\n\nETL\n\n\n \n\n\n\n\nApr 16, 2023\n\n\nTobias\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/brem-stylized.html",
    "href": "projects/brem-stylized.html",
    "title": "Stylized Map of Bremen",
    "section": "",
    "text": "tl;dr: Drawing a beautiful map of my hometown Bremen as an exercise in dealing with geospatial data. This post is heavily inspired by this one from Timo Grossenbacher."
  },
  {
    "objectID": "projects/brem-stylized.html#the-data",
    "href": "projects/brem-stylized.html#the-data",
    "title": "Stylized Map of Bremen",
    "section": "The data",
    "text": "The data\nAll of the data I used is available from official sources for free. Although I’m not allowed to provide it directly, I’ll do my best to describe what exactly I used and where you’d get it.\nThe different elements of the map come from these shapefiles:\n\nGeography: Instead of using only drawn borders, I’m going for a more organic look. I used the geographies from this INSPIRE dataset.\nCity districts: Or “Verwaltungsgrenzen” as we say in Germany; we’re using hb_ortsteile_BRE.shp.\nBuildings: Or “Liegenschaften”, yet another beautiful german administration term; GebaeudeBauwerk.shp.\nWater bodies: The shapefile for all things water-y is gew01_f.shp and comes from the “Basis DLM”.\nTrain tracks: I like trains and public transport. Again, the file from the Basis DLM is ver03_l.shp.\nStreets: A file of the “Strassennetz”, containing pretty much what it says on the tin.\n\nI also used the Google font Playfair Display for all text. I’ll just assume you know how to get, install and make it available to R/ggplot2 - I used the extrafont package to do so."
  },
  {
    "objectID": "projects/brem-stylized.html#theme-and-colors",
    "href": "projects/brem-stylized.html#theme-and-colors",
    "title": "Stylized Map of Bremen",
    "section": "Theme and colors",
    "text": "Theme and colors\nTo make experimentation easier, I defined the colors and other general aesthetic elements in a separate file.\n\n## colors\ncol_plot_bg &lt;- \"#faf3e1\"\ncol_strokes &lt;- \"#443525\"\ncol_areas   &lt;- \"#efe8e1\"\ncol_water   &lt;- \"#405a75\"\n\npergamono &lt;- c(\"#201912\", \"#413324\", \"#624c36\",\n               \"#836648\", \"#a4805a\", \"#b6997b\",\n               \"#c8b29c\", \"#daccbd\", \"#ece5de\")\n\ncolors_zentrum &lt;- c(\"#bfa58a\",\"#bfb289\",\"#bebf89\",\n                    \"#b1bf89\",\"#a3bf89\",\"#96bf89\")\n\ncolors_ostvor &lt;- c(\"#bfa58a\", \"#96bf89\", \"#bfb289\", \"#bebf89\")\n\n## ggplot theme & defaults\ntheme_set(\n  theme_void() +\n    theme(\n      legend.position = \"none\",\n      panel.border = element_rect(fill = NA, color = col_strokes),\n      panel.background = element_rect(fill = col_plot_bg),\n      plot.background =  element_rect(fill = col_plot_bg),\n      strip.background = element_rect(fill = col_plot_bg),\n    )\n)\n\nupdate_geom_defaults(\"point\", list(colour = col_strokes))\nupdate_geom_defaults(\"line\", list(colour = col_strokes))\nupdate_geom_defaults(\"area\", list(colour = \"transparent\",\n                                  fill   = pergamono[8]))\nupdate_geom_defaults(\"rect\", list(colour = \"transparent\",\n                                  fill   = pergamono[8]))\nupdate_geom_defaults(\"sf\", list(colour = \"transparent\",\n                                fill   = pergamono[8]))\nupdate_geom_defaults(\"density\", list(colour = col_strokes,\n                                     fill   = pergamono[8]))\nupdate_geom_defaults(\"bar\", list(colour = col_plot_bg,\n                                 fill   = pergamono[8]))\nupdate_geom_defaults(\"col\", list(colour = col_plot_bg,\n                                 fill   = pergamono[8]))\nupdate_geom_defaults(\"text\", list(colour = pergamono[2]))\nupdate_geom_defaults(\"label\", list(colour = pergamono[2]))"
  },
  {
    "objectID": "projects/brem-stylized.html#preparing-the-map",
    "href": "projects/brem-stylized.html#preparing-the-map",
    "title": "Stylized Map of Bremen",
    "section": "Preparing the Map",
    "text": "Preparing the Map\nNot every shapefile is projected onto the same CRS, so that has to change. Also, I only want to plot the city of Bremen and a little of the surroundings. Zooming-in to the Östliche Vorstadt (the “Viertel”) needs a lot of subsetting, especially of the shapefile containing the buildings. Needless to say, the file paths are not reproducible at all and you’d have to adjust them to suit your setup.\n\nMain Map - The Whole City\n\ngeografie &lt;- read_sf(\"shapefiles/Geologische_Karte/gk_gdfb_052024_inspire_HB.shp\") %&gt;%\n  st_transform(crs = \"EPSG:5677\") %&gt;%\n  mutate(y = st_coordinates(st_centroid(.))[, 2]) %&gt;%\n  filter(y &lt; 5890000) %&gt;%\n  st_make_valid() %&gt;%\n  select(-y)\nax_gewaesser &lt;- read_sf(\"shapefiles/Basis_DLM/gew01_f.shp\") %&gt;%\n  st_transform(crs = \"EPSG:5677\")\n\nortsteile &lt;- read_sf(\"shapefiles/Verwaltungsgrenzen/hb_ortsteile_BRE.shp\") %&gt;%\n  st_transform(crs = \"EPSG:5677\")\nzentrum &lt;- ortsteile %&gt;%\n  filter(bez_st %in% c(\"Mitte\", \"Neustadt\", \"Östliche Vorstadt\",\n                       \"Schwachhausen\", \"Findorff\"),\n         !(bez_ot %in% c(\"In den Hufen\", \"Riensberg\", \"Huckelriede\",\n                         \"Radio Bremen\", \"Neuenland\", \"Neu-Schwachhausen\")))\n\nstrassen &lt;- read_sf(\"shapefiles/Strassennetz/Strassennetz.shp\") %&gt;%\n  st_transform(crs = \"EPSG:5677\") %&gt;%\n  mutate(y = st_coordinates(st_centroid(.))[, 2]) %&gt;%\n  filter(y &lt; 5920000, StrassenAr != \"G\") %&gt;%\n  select(-y)\nax_bahnstrecke &lt;- read_sf(\"shapefiles/Basis_DLM/ver03_l.shp\") %&gt;%\n  st_transform(crs = \"EPSG:5677\")\n\n\n\nZoomed Area - Östliche Vorstadt\nSince buildings are only needed in the sub-plot and the respective shapefile is rather huge, I actually factored out the subsetting of the parts I need - see prep_buildings.R script in the github repository.\n\nostvor &lt;- ortsteile %&gt;%\n  filter(bez_st == \"Östliche Vorstadt\")\nbauwerke &lt;- read_sf(\"shapefiles/Liegenschaften/GebaeudeBauwerk.shp\") %&gt;%\n  st_transform(crs = \"EPSG:5677\")\n\nzentrum_bauwerke &lt;- bauwerke[zentrum, ]\nostvor_bauwerke  &lt;- zentrum_bauwerke[ostvor, ]\n\nostvor_buff &lt;- ostvor %&gt;%\n  st_centroid() %&gt;%\n  st_buffer(1000) \n\nostvor_bbox &lt;- ostvor_buff %&gt;%\n  st_bbox() %&gt;%\n  st_as_sfc()\nbbox_wasser &lt;- ostvor_buff %&gt;%\n  st_bbox() %&gt;%\n  st_as_sfc() %&gt;%\n  st_intersection(ax_gewaesser)\nbbox_bauwerke &lt;- ostvor_bbox %&gt;% \n  st_intersection(bauwerke)\n\nI also create a tibble to make the annotations somewhat more data-driven1. I did some legwork to find the coordinates for the labels, see the bonus bit at the end.\n\nostvor_centroids &lt;- ostvor %&gt;%\n  st_centroid() %&gt;%\n  st_coordinates() %&gt;%\n  as_tibble()\n\nostvor_annotations &lt;- tibble(\n  ortsteil = ostvor$bez_ot,\n  x = c(3487947, 3489651, 3488957, 3488278),\n  xend = ostvor_centroids$X,\n  y = c(5882982, 5883134, 5880991, 5881416),\n  yend = ostvor_centroids$Y,\n  curvature = c(0.2, 0.1, -0.1, -0.2),\n  nudge_x = c(0, 50, -50, -50),\n  nudge_y = c(50, 0, 0, 0),\n  hjust = c(.5, 0, 1, 1),\n  vjust = c(0, .5, .5, .5)\n)"
  },
  {
    "objectID": "projects/brem-stylized.html#get-mappin",
    "href": "projects/brem-stylized.html#get-mappin",
    "title": "Stylized Map of Bremen",
    "section": "Get mappin’!",
    "text": "Get mappin’!\nNow to create the actual map. One final bit beforehand is a somewhat hack-ish approach to get rid of bits of districts or the geography that overlaps with the water bodies. This is not a very clean or even necessary thing to do, but while working on the map I liked to adjust the transparancy of the water color instead of the water color itself. I encourage you to plot the map with and without these bits to get a better idea of what I mean.\n\ninter_geografie &lt;- st_intersection(ax_gewaesser, geografie)\ninter_zentrum   &lt;- st_intersection(ax_gewaesser, zentrum)\ninter_ostvor &lt;- st_intersection(bbox_wasser, ostvor)\n\n\nMain Map\n\nmain_area &lt;- ggplot() +\n  scale_fill_manual(values = colors_zentrum) +\n  scale_color_manual(values = colors_zentrum) +\n  geom_sf(data = geografie) +\n  geom_sf(data = inter_geografie, fill = col_plot_bg) +\n  geom_sf(data = zentrum, aes(fill = bez_st)) +\n  geom_sf(data = inter_zentrum, fill = col_plot_bg) +\n  # use st_buffer() to make tracks, streets and water bodies look more organic\n  geom_sf(data = ax_gewaesser[st_buffer(ortsteile, 1000), ], \n          fill = col_water, alpha = .8) +\n  geom_sf(data = ax_bahnstrecke[st_buffer(ortsteile, 1500), ],\n          color = \"#624c36\", linewidth = .3, linetype = 6) +\n  geom_sf(data = strassen[st_buffer(ortsteile, 1200), ],\n          color = \"#a4a4a4\", linewidth = .5) +\n  geom_text(aes(x = 3502357, y = 5899710, label = \"Hansestadt Bremen\"),\n            family = \"Playfair Display ExtraBold\", size.unit = \"pt\", size = 44,\n            hjust = 1, vjust = 1) +\n  # draw a rectangle around the area we're about zoom-in on\n  geom_sf(data = ostvor_bbox,\n          fill = \"transparent\", color = pergamono[3],\n          linetype = \"5151\", linewidth = .75)\n\n\n\nZoomed Area\n\nzoom_area &lt;- ggplot() +\n  scale_fill_manual(values = colors_ostvor) +\n  scale_color_manual(values = colors_ostvor) +\n  geom_sf(data = ostvor, aes(fill = bez_ot), \n          alpha = 1, color = col_plot_bg) +\n  geom_sf(data = inter_ostvor, fill = col_plot_bg) +\n  geom_sf(data = bbox_wasser, fill = col_water, alpha = .8) +\n  geom_sf(data = bbox_bauwerke, color = pergamono[8]) +\n  geom_sf(data = ostvor_bauwerke, color = pergamono[5]) +\n  geom_curve(data = ostvor_annotations, curvature = .2,\n             aes(x = x, xend = xend, y = y, yend = yend),\n             color = pergamono[3]) +\n  geom_label(data = ostvor_annotations, family = \"Playfair Display Medium\",\n             aes(x = x, y = y, label = ortsteil, hjust = hjust, vjust = vjust),\n             nudge_x = ostvor_annotations$nudge_x, nudge_y = ostvor_annotations$nudge_y,\n             alpha = .6, fill = col_plot_bg, label.padding = unit(0.2, \"lines\"),\n             label.r = unit(0.1, \"lines\"), label.size = 0, color = pergamono[2]) +\n  geom_label(aes(x = 3487664, y = 5883384, label = \"Östliche Vorstadt\"),\n             family = \"Playfair Display SemiBold\", size.unit = \"pt\", size = 20,\n             alpha = .6, fill = col_plot_bg, label.padding = unit(0.2, \"lines\"),\n             label.r = unit(0.1, \"lines\"), label.size = 0,\n             hjust = 0, vjust = 0, nudge_x = -30)\n\n\n\nTying it all together\nI use the patchwork package to place the zoomed area on the bottom-left of the main area.\n\nmain_area + inset_element(\n  zoom_area,\n  right = .4,\n  top = .6,\n  left = unit(0, 'npc') + unit(.5, 'cm'),\n  bottom = unit(0, 'npc') + unit(.5, 'cm')\n)"
  },
  {
    "objectID": "projects/brem-stylized.html#footnotes",
    "href": "projects/brem-stylized.html#footnotes",
    "title": "Stylized Map of Bremen",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAgain, credit goes to Timo’s work for this part in particular!↩︎"
  },
  {
    "objectID": "projects/sugr-prep.html",
    "href": "projects/sugr-prep.html",
    "title": "sugr: data preparation",
    "section": "",
    "text": "tl;dr: CGMs are a great source of (timeseries) data to tinker with. Here I describe the process of cleaning up and preparing the data of Medtronics systems in order to use it in a shiny app."
  },
  {
    "objectID": "projects/sugr-prep.html#codebook",
    "href": "projects/sugr-prep.html#codebook",
    "title": "sugr: data preparation",
    "section": "Codebook",
    "text": "Codebook\nThe variables of interest are:\n\n\n\n\n\n\n\n\n\nVariable\nRenamed to\nDescription\n\n\n\n\nIndex\nindex\nkinda self-explanatory\n\n\nDate\ndate\nYear-Month-Day\n\n\nTime\ntime\nhh:mm:ss\n\n\nBG Reading (mg/dL)\nbg_direct\na direct measurement of blood, usually by pricking a finger\n\n\nSensor Glucose (mg/dL)\nbg_sensor\nan indirect measurement of interstitial fluid by the gcm sensor\n\n\nBasal Rate (U/h)\nbasal_rate\nthe hourly rate of insulin given (in ‘Units’; roughly 100U/ml)\n\n\nBWZ BG Input (mg/dL)\nwiz_bg\nblood glucose level (manual input)\n\n\nBWZ Carb Input (grams)\nwiz_carbs\ncarbohydrates (manual input)\n\n\nBWZ Carb Ratio (g/U)\nwiz_ratio\nratio of carbs per unit of insulin\n\n\nBWZ Correction Estimate (U)\nwiz_est_correction\ninsulin to deliver to correct for too high bg level\n\n\nBWZ Food Estimate (U)\nwiz_est_food\ninsulin units to deliver for the amount of carbohydrates (carbs / ratio)\n\n\nBWZ Unabsorbed Insulin Total (U)\nwiz_est_unabsorbed\ninsulin to not deliver in order to not overcompensate\n\n\nFinal Bolus Estimate\nbolus_final\namount of insulin to deliver\n\n\nBolus Volume Delivered (U)\nbolus_delivered\nthe actual amount of insulin delivered"
  },
  {
    "objectID": "projects/sugr-prep.html#cleaning-and-variable-selection",
    "href": "projects/sugr-prep.html#cleaning-and-variable-selection",
    "title": "sugr: data preparation",
    "section": "Cleaning and Variable Selection",
    "text": "Cleaning and Variable Selection\nTo clean up column names, we could of course use some convenient helper function like clean_names() from the janitor package:\n\njanitor::clean_names(data_raw) %&gt;% names() %&gt;% sort()\n\n [1] \"alarm\"                               \"basal_rate_u_h\"                     \n [3] \"bg_reading_mg_d_l\"                   \"bg_source\"                          \n [5] \"ble_network_device\"                  \"bolus_cancellation_reason\"          \n [7] \"bolus_duration_h_mm_ss\"              \"bolus_number\"                       \n [9] \"bolus_source\"                        \"bolus_type\"                         \n[11] \"bolus_volume_delivered_u\"            \"bolus_volume_selected_u\"            \n[13] \"bwz_active_insulin_u\"                \"bwz_bg_input_mg_d_l\"                \n[15] \"bwz_carb_input_grams\"                \"bwz_carb_ratio_g_u\"                 \n[17] \"bwz_correction_estimate_u\"           \"bwz_estimate_u\"                     \n[19] \"bwz_food_estimate_u\"                 \"bwz_insulin_sensitivity_mg_d_l_u\"   \n[21] \"bwz_status\"                          \"bwz_target_high_bg_mg_d_l\"          \n[23] \"bwz_target_low_bg_mg_d_l\"            \"bwz_unabsorbed_insulin_total_u\"     \n[25] \"date\"                                \"event_marker\"                       \n[27] \"final_bolus_estimate\"                \"index\"                              \n[29] \"insulin_action_curve_time\"           \"isig_value\"                         \n[31] \"linked_bg_meter_id\"                  \"network_device_associated_reason\"   \n[33] \"network_device_disassociated_reason\" \"network_device_disconnected_reason\" \n[35] \"new_device_time\"                     \"preset_bolus\"                       \n[37] \"preset_temp_basal_name\"              \"prime_type\"                         \n[39] \"prime_volume_delivered_u\"            \"rewind\"                             \n[41] \"scroll_step_size\"                    \"sensor_calibration_bg_mg_d_l\"       \n[43] \"sensor_calibration_rejected_reason\"  \"sensor_exception\"                   \n[45] \"sensor_glucose_mg_d_l\"               \"suspend\"                            \n[47] \"temp_basal_amount\"                   \"temp_basal_duration_h_mm_ss\"        \n[49] \"temp_basal_type\"                     \"time\"                               \n[51] \"x51\"                                \n\n\nAs you can see, that does indeed make them “workable”, but it’s still pretty convoluted and even occasionally confusing. Therefore, in a second step, we do some touch-ups manually and get rid of all the columns we’re not interested in. And since we’re already at it, why not tick off the rest of the items on our list, too?\n\ndata_full &lt;- data_raw %&gt;% \n  janitor::clean_names() %&gt;% \n  transmute(\n    index = index,\n    datetime = round_date(ymd_hms(paste(date, time)), unit = \"minute\"),\n    date  = date,\n    wday  = wday(date, label = TRUE, week_start = 1),\n    time  = time,\n    basal_rate = basal_rate_u_h,\n    bg_direct  = bg_reading_mg_d_l,\n    bg_sensor  = sensor_glucose_mg_d_l,\n    wiz_ratio = bwz_carb_ratio_g_u,\n    wiz_carbs = bwz_carb_input_grams,\n    wiz_bg = bwz_bg_input_mg_d_l,\n    wiz_est_correction = bwz_correction_estimate_u,\n    wiz_est_food = bwz_food_estimate_u,\n    wiz_est_unabsorbed = bwz_unabsorbed_insulin_total_u,\n    bolus_final = final_bolus_estimate, \n    bolus_delivered = bolus_volume_delivered_u\n  )\n\nWarning: There was 1 warning in `transmute()`.\nℹ In argument: `datetime = round_date(ymd_hms(paste(date, time)), unit =\n  \"minute\")`.\nCaused by warning:\n!  2 failed to parse."
  },
  {
    "objectID": "projects/sugr-prep.html#section",
    "href": "projects/sugr-prep.html#section",
    "title": "sugr: data preparation",
    "section": "",
    "text": "Another Warning, this time a parsing failure? Most certainly either when calling for the weekday labels or concoctenating and rounding the datetime:\n\nanyNA(data_full$wday)\n\n[1] TRUE\n\ndata_full %&gt;% \n  filter(is.na(wday)) %&gt;% \n  glimpse()\n\nRows: 2\nColumns: 16\n$ index              &lt;dbl&gt; NA, NA\n$ datetime           &lt;dttm&gt; NA, NA\n$ date               &lt;date&gt; NA, NA\n$ wday               &lt;ord&gt; NA, NA\n$ time               &lt;time&gt; NA, NA\n$ basal_rate         &lt;dbl&gt; NA, NA\n$ bg_direct          &lt;dbl&gt; NA, NA\n$ bg_sensor          &lt;dbl&gt; NA, NA\n$ wiz_ratio          &lt;dbl&gt; NA, NA\n$ wiz_carbs          &lt;dbl&gt; NA, NA\n$ wiz_bg             &lt;dbl&gt; NA, NA\n$ wiz_est_correction &lt;dbl&gt; NA, NA\n$ wiz_est_food       &lt;dbl&gt; NA, NA\n$ wiz_est_unabsorbed &lt;dbl&gt; NA, NA\n$ bolus_final        &lt;dbl&gt; NA, NA\n$ bolus_delivered    &lt;dbl&gt; NA, NA\n\n\nTwo completely empty rows alright. Since even the index column is empty, it’s probably just an artefact of the “two datasets in one file issue”. We better check that out, too, though.\n\nFind SuspectsGlimpse\n\n\n\nanyNA(data_raw$Index)\n\n[1] TRUE\n\nwhich(is.na(data_raw$Index))\n\n[1] 4337 4338\n\n\n\n\n\ndata_raw[4336:4339, ] %&gt;% \n  glimpse()\n\nRows: 4\nColumns: 51\n$ Index                                 &lt;dbl&gt; 4335, NA, NA, 4336\n$ Date                                  &lt;date&gt; 2022-01-30, NA, NA, 2022-02-17\n$ Time                                  &lt;time&gt; 23:50:04,       NA,       NA, 11…\n$ `New Device Time`                     &lt;lgl&gt; NA, NA, NA, NA\n$ `BG Source`                           &lt;chr&gt; NA, \"-------\", \"BG Source\", NA\n$ `BG Reading (mg/dL)`                  &lt;dbl&gt; NA, NA, NA, NA\n$ `Linked BG Meter ID`                  &lt;chr&gt; NA, NA, \"Linked BG Meter ID\", NA\n$ `Basal Rate (U/h)`                    &lt;dbl&gt; NA, NA, NA, NA\n$ `Temp Basal Amount`                   &lt;lgl&gt; NA, NA, NA, NA\n$ `Temp Basal Type`                     &lt;lgl&gt; NA, NA, NA, NA\n$ `Temp Basal Duration (h:mm:ss)`       &lt;lgl&gt; NA, NA, NA, NA\n$ `Bolus Type`                          &lt;chr&gt; NA, NA, \"Bolus Type\", NA\n$ `Bolus Volume Selected (U)`           &lt;dbl&gt; NA, NA, NA, NA\n$ `Bolus Volume Delivered (U)`          &lt;dbl&gt; NA, NA, NA, NA\n$ `Bolus Duration (h:mm:ss)`            &lt;lgl&gt; NA, NA, NA, NA\n$ `Prime Type`                          &lt;chr&gt; NA, NA, \"Prime Type\", NA\n$ `Prime Volume Delivered (U)`          &lt;dbl&gt; NA, NA, NA, NA\n$ Alarm                                 &lt;chr&gt; NA, NA, \"Alarm\", NA\n$ Suspend                               &lt;chr&gt; NA, NA, \"Suspend\", NA\n$ Rewind                                &lt;lgl&gt; NA, NA, NA, NA\n$ `BWZ Estimate (U)`                    &lt;dbl&gt; NA, NA, NA, NA\n$ `BWZ Target High BG (mg/dL)`          &lt;lgl&gt; NA, NA, NA, NA\n$ `BWZ Target Low BG (mg/dL)`           &lt;lgl&gt; NA, NA, NA, NA\n$ `BWZ Carb Ratio (g/U)`                &lt;dbl&gt; NA, NA, NA, NA\n$ `BWZ Insulin Sensitivity (mg/dL/U)`   &lt;lgl&gt; NA, NA, NA, NA\n$ `BWZ Carb Input (grams)`              &lt;dbl&gt; NA, NA, NA, NA\n$ `BWZ BG Input (mg/dL)`                &lt;dbl&gt; NA, NA, NA, NA\n$ `BWZ Correction Estimate (U)`         &lt;dbl&gt; NA, NA, NA, NA\n$ `BWZ Food Estimate (U)`               &lt;dbl&gt; NA, NA, NA, NA\n$ `BWZ Active Insulin (U)`              &lt;lgl&gt; NA, NA, NA, NA\n$ `BWZ Status`                          &lt;chr&gt; NA, NA, \"BWZ Status\", NA\n$ `Sensor Calibration BG (mg/dL)`       &lt;dbl&gt; NA, NA, NA, NA\n$ `Sensor Glucose (mg/dL)`              &lt;dbl&gt; NA, NA, NA, 122\n$ `ISIG Value`                          &lt;dbl&gt; NA, NA, NA, 23.9\n$ `Event Marker`                        &lt;chr&gt; NA, NA, \"Event Marker\", NA\n$ `Bolus Number`                        &lt;dbl&gt; NA, NA, NA, NA\n$ `Bolus Cancellation Reason`           &lt;lgl&gt; NA, NA, NA, NA\n$ `BWZ Unabsorbed Insulin Total (U)`    &lt;dbl&gt; NA, NA, NA, NA\n$ `Final Bolus Estimate`                &lt;dbl&gt; NA, NA, NA, NA\n$ `Scroll Step Size`                    &lt;chr&gt; NA, NA, \"Scroll Step Size\", NA\n$ `Insulin Action Curve Time`           &lt;lgl&gt; NA, NA, NA, NA\n$ `Sensor Calibration Rejected Reason`  &lt;lgl&gt; NA, NA, NA, NA\n$ `Preset Bolus`                        &lt;lgl&gt; NA, NA, NA, NA\n$ `Bolus Source`                        &lt;chr&gt; NA, NA, \"Bolus Source\", NA\n$ `BLE Network Device`                  &lt;lgl&gt; NA, NA, NA, NA\n$ `Network Device Associated Reason`    &lt;lgl&gt; NA, NA, NA, NA\n$ `Network Device Disassociated Reason` &lt;lgl&gt; NA, NA, NA, NA\n$ `Network Device Disconnected Reason`  &lt;lgl&gt; NA, NA, NA, NA\n$ `Sensor Exception`                    &lt;chr&gt; NA, NA, \"Sensor Exception\", NA\n$ `Preset Temp Basal Name`              &lt;lgl&gt; NA, NA, NA, NA\n$ ...51                                 &lt;lgl&gt; NA, NA, NA, NA\n\n\n\n\n\nThat confirms it. Actually, we should throw those lines out right at the beginning of the process."
  },
  {
    "objectID": "projects/sugr-prep.html#wrap-up",
    "href": "projects/sugr-prep.html#wrap-up",
    "title": "sugr: data preparation",
    "section": "Wrap-Up",
    "text": "Wrap-Up\nDoing it all in one go might then look like this:\n\ndata_full &lt;- read_delim(\"data/sugr/carelink-export-220217.csv\", \n                  delim = \";\", escape_double = FALSE, \n                  col_types = cols(Date = col_date(format = \"%Y/%m/%d\"), \n                                   Time = col_time(format = \"%H:%M:%S\")), \n                  locale = locale(decimal_mark = \",\"), \n                  trim_ws = TRUE, skip = 6) %&gt;% \n  janitor::clean_names() %&gt;% \n  filter(!is.na(index)) %&gt;% \n  transmute(\n    index              = index,\n    datetime_rounded   = round_date(ymd_hms(paste(date, time)), unit = \"minute\"),\n    datetime           = ymd_hms(paste(date, time)),\n    date               = date,\n    wday               = wday(date, label = TRUE, week_start = 1),\n    time               = time,\n    basal_rate         = basal_rate_u_h,\n    bg_direct          = bg_reading_mg_d_l,\n    bg_sensor          = sensor_glucose_mg_d_l,\n    wiz_ratio          = bwz_carb_ratio_g_u,\n    wiz_carbs          = bwz_carb_input_grams,\n    wiz_bg             = bwz_bg_input_mg_d_l,\n    wiz_est_correction = bwz_correction_estimate_u,\n    wiz_est_food       = bwz_food_estimate_u,\n    wiz_est_unabsorbed = bwz_unabsorbed_insulin_total_u,\n    bolus_final        = final_bolus_estimate, \n    bolus_delivered    = bolus_volume_delivered_u\n  )"
  },
  {
    "objectID": "projects/sugr-prep.html#footnotes",
    "href": "projects/sugr-prep.html#footnotes",
    "title": "sugr: data preparation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nmostly hard-coded things like ratios or target values that change slightly during a day but stay the same across all days↩︎\nother variables contain aforementioned “hard codings” or diagnostics on device usage such as low battery warnings↩︎\nwith an unspecific shift happening once a week whenever the sensor has to be replaced↩︎\nActually, a third possibility is the extraction of only those empty rows within the CGM block, but losing the context in which they appear is not very practical.↩︎"
  },
  {
    "objectID": "projects/sugr-shiny.html",
    "href": "projects/sugr-shiny.html",
    "title": "sugr: make it shiny",
    "section": "",
    "text": "tl;dr:\n\nhere’s a shiny app to explore CGM data\nhere’s the code\nsee this post for the data-cleanup procedure"
  },
  {
    "objectID": "projects/sugr-shiny.html#footnotes",
    "href": "projects/sugr-shiny.html#footnotes",
    "title": "sugr: make it shiny",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere is no way to just manually tell the pump to inject insulin and the workaround is to do that via pseudo-carb-intake.↩︎"
  }
]